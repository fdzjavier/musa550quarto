{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d57ceb8-423f-4b70-9914-8826a01d1365",
   "metadata": {},
   "source": [
    "---\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "execute:\n",
    "  echo: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa76e04-679f-4edc-a7ea-437dd749e986",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Zip Code Preparation\n",
    "\n",
    "Cleaning the ZIP Code data to show the ZHVI changes from 2020-2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23d3d96-c172-46c1-99ab-2163584cbe68",
   "metadata": {},
   "source": [
    "Start by importing the packages we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228cd6f6-0e39-479c-a4fe-21f3c7dab503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# URL of the Zip Code JSON file\n",
    "url = \"https://og-production-open-data-newarknj-892364687672.s3.amazonaws.com/resources/e801054d-2392-4413-af40-042e9bc986b9/njzctapolygon.geojson?Content-Type=application%2Fjson&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAJJIENTAPKHZMIPXQ%2F20240515%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240515T045045Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=f905d5c756751b7a2b8eb871f028ee3fddc6af4c1ca3688902e44b08008b3f53\"\n",
    "\n",
    "# Fetch the JSON data\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf6caaf-210a-4185-9c87-190aad7b6ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import folium\n",
    "\n",
    "# Load GeoJSON data into a GeoDataFrame\n",
    "zipcodes = gpd.read_file(\"njzctapolygon.geojson\")\n",
    "\n",
    "# Display the first few rows of the attribute table\n",
    "print(zipcodes.head())\n",
    "\n",
    "# Create a map centered at the mean of geometry coordinates\n",
    "zipcodes_map = folium.Map(location=[zipcodes.geometry.centroid.y.mean(), zipcodes.geometry.centroid.x.mean()], zoom_start=10)\n",
    "\n",
    "# Add GeoJSON data to the map\n",
    "folium.GeoJson(zipcodes).add_to(zipcodes_map)\n",
    "\n",
    "# Save the map as an HTML file\n",
    "zipcodes_map.save(\"zipcodes.html\")\n",
    "\n",
    "# Display the map\n",
    "zipcodes_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8950acac-e74d-4a63-9784-48f41c155959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "zillow_data = pd.read_csv(\"./data/zillowdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338097dd-faf9-44c1-9eff-c29093a01c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'RegionName' column to strings in order to add the leading \"0\" to the Zip Codes\n",
    "Newark_NJ_zillow_data['RegionName'] = Newark_NJ_zillow_data['RegionName'].astype(str)\n",
    "\n",
    "# Since Newark Zip Codes start with zero, python appears to be omitting them\n",
    "# Add leading zeros to Zip Codes\n",
    "Newark_NJ_zillow_data['RegionName'] = Newark_NJ_zillow_data['RegionName'].str.zfill(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89c5708-5850-46db-8544-26a0e43b2cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def looks_like_a_date(column_name):\n",
    "    return column_name.startswith(\"20\")\n",
    "\n",
    "list(\n",
    "    filter(looks_like_a_date, zillow_data.columns)\n",
    ")\n",
    "    \n",
    "pd.melt(\n",
    "    Newark_NJ_zillow_data,\n",
    "    id_vars = [\"City\",\"State\",\"RegionName\"],\n",
    "    value_vars = list(\n",
    "        filter(looks_like_a_date, Newark_NJ_zillow_data.columns)\n",
    "    ),\n",
    "    var_name = \"Date\",\n",
    "    value_name = \"ZHVI\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6551872-ceb8-4cdb-ba2f-93a3fe318f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "newark_zhvi_tidy = Newark_NJ_zillow_data.melt(\n",
    "    id_vars=[\"City\", \"StateName\",\"RegionName\"],\n",
    "    value_vars=list(filter(looks_like_a_date, Newark_NJ_zillow_data.columns)), \n",
    "    var_name=\"Date\",\n",
    "    value_name=\"ZHVI\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d79c94-7976-4091-8ce3-55fef38322b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_percent_increase(grouped_newark):\n",
    "    \"\"\"\n",
    "    Calculate the percent increase from 2020-03-31 to 2024-03-31.\n",
    "    \n",
    "    Note that `group_df` is the DataFrame for each group.\n",
    "    \"\"\"\n",
    "    \n",
    "    march20_sel = grouped_newark[\"Date\"] == \"2020-03-31\"\n",
    "    march22_sel = grouped_newark[\"Date\"] == \"2022-03-31\"\n",
    "    \n",
    "    # Get the data for each month (only 1 row, so squeeze it!)\n",
    "    march_2020 = grouped_newark.loc[march20_sel].squeeze()\n",
    "    march_2022 = grouped_newark.loc[march22_sel].squeeze()\n",
    "\n",
    "    # Columns to calculate percent change for\n",
    "    columns = [\"ZHVI\"]\n",
    "    \n",
    "    # Return the percent change for both columns\n",
    "    return 100 * (march_2022[columns] / march_2020[columns] - 1)\n",
    "\n",
    "grouped_newark = newark_zhvi_tidy.groupby(\"RegionName\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb549c6d-74e3-4fb4-92fa-3242835c38d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ZHVI Percent Increase for newark area \n",
    "result_newark = grouped_newark.apply(calculate_percent_increase)\n",
    "result_newark.sort_values(by=\"ZHVI\", ascending=True)\n",
    "print(result_newark)\n",
    "\n",
    "#Avg change to zillow prices for Rest of newark\n",
    "result_newark.mean()\n",
    "print(\"Average change to ZHVI prices in Rest of newark:\", result_newark.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad06fe79-35ef-47cb-8b93-b67165bc16a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge zip code geometry with zillow zip code data\n",
    "merged_zillow = zipcodes.merge(result_newark, left_on='GEOID10', right_on='RegionName', how='left')\n",
    "\n",
    "# Save the merged GeoDataFrame as a new GeoJSON file\n",
    "merged_zillow.to_file(\"merged_data.geojson\", driver='GeoJSON')\n",
    "\n",
    "#drop unnecessary columns\n",
    "merged_zillow = merged_zillow.drop(columns=['ZCTA5CE10', 'CLASSFP10', 'MTFCC10','FUNCSTAT10','ALAND10','AWATER10'])\n",
    "\n",
    "#rename columns\n",
    "merged_zillow = merged_zillow.rename(columns={'INTPTLAT10': 'lat', 'INTPTLON10': 'lon', 'GEOID10': 'geoid'})\n",
    "\n",
    "merged_zillow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c863300e-a32c-4393-92d1-9aedf35c16a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_prices_newark = merged_df['ZHVI'].mean()\n",
    "print(\"Newark ZHVI Average Across Neighborhoods from 2020-2022:\",avg_prices_newark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fd3386-1691-4d7b-8d6b-a23fa8341bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the GeoDataFrame\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "merged_df.plot(ax=ax, column='ZHVI', legend=True)\n",
    "plt.title('Avg ZHVI Change from 2020-2022 across Zip Codes')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddbdeda-e7a1-4169-9e46-d2200a5a4fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Census demographic variables\n",
    "variables = [\n",
    "    \"NAME\",\n",
    "    \"B03002_001E\",\n",
    "    \"B03002_003E\", \n",
    "    \"B03002_004E\", \n",
    "    \"B03002_005E\", \n",
    "    \"B03002_006E\", \n",
    "    \"B03002_007E\", \n",
    "    \"B03002_008E\", \n",
    "    \"B03002_009E\", \n",
    "    \"B03002_012E\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5baf37-1983-433a-8576-ddd7aa000a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cenpy\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "censustracts = gpd.read_file('./data/tracts2019.geojson')\n",
    "censustracts = censustracts[['GEOID','NAMELSAD', 'Pop_Total', 'Pop_Total_Poverty','Pop_Edu_NoHS_Pct','geometry']]\n",
    "censustracts = censustracts.rename(columns = {'GEOID':'geoid'})\n",
    "censustracts = censustracts.rename(columns = {'NAMELSAD':'tract'})\n",
    "censustracts = censustracts.rename(columns = {'Pop_Total':'totalpop'})\n",
    "censustracts = censustracts.rename(columns = {'Pop_Total_Poverty':'poverty'})\n",
    "censustracts = censustracts.rename(columns = {'Pop_Edu_NoHS_Pct':'noeducation'})\n",
    "censustracts['geoid'] = censustracts['geoid'].astype(np.int64)\n",
    "\n",
    "# create a new column that creates the tract ID from the GEOID column\n",
    "censustracts['tract'] = censustracts['geoid'].astype(str).str[5:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e96fd14-23db-4e1f-b0ae-b27457e4f1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "available = cenpy.explorer.available()\n",
    "acs = cenpy.remote.APIConnection(\"ACSDT5Y2021\")\n",
    "newark_county_code = \"013\"\n",
    "nj_state_code = \"34\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d439b258-e4a5-4df7-9f8c-7a86fb0c06b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# queries a table\n",
    "newark_demographics = acs.query(\n",
    "    cols=variables,\n",
    "    geo_unit=\"block group:*\",\n",
    "    geo_filter={\"state\": nj_state_code, \"county\": newark_county_code, \"tract\": \"*\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc87673a-f304-494c-9b29-33e31c87b283",
   "metadata": {},
   "outputs": [],
   "source": [
    "newark_demographics = newark_demographics.rename(\n",
    "    columns={\n",
    "        \"B03002_001E\": \"Total\", \n",
    "        \"B03002_003E\": \"White\",  \n",
    "        \"B03002_004E\": \"Black\",  \n",
    "        \"B03002_005E\": \"AI/AN\", \n",
    "        \"B03002_006E\": \"Asian\",  \n",
    "        \"B03002_007E\": \"NH/PI\", \n",
    "        \"B03002_008E\": \"Other_\",  \n",
    "        \"B03002_009E\": \"Two Plus\",\n",
    "        \"B03002_012E\": \"Hispanic\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c8102e-32b1-4ef5-b60d-22a5174f9592",
   "metadata": {},
   "outputs": [],
   "source": [
    "newark_demographics = pd.merge(newark_demographics, censustracts, on='tract', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa5876c-c540-43eb-ac70-2a6d02e0df33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create percentages of race/ethnicity\n",
    "newark_demographics['Black'] = pd.to_numeric(newark_demographics['Black'])\n",
    "newark_demographics['Total'] = pd.to_numeric(newark_demographics['Total'])\n",
    "newark_demographics['blk_percent'] = (newark_demographics['Black'] / newark_demographics['Total']) * 100\n",
    "newark_demographics['White'] = pd.to_numeric(newark_demographics['White'])\n",
    "newark_demographics['white_percent'] = (newark_demographics['White'] / newark_demographics['Total']) * 100\n",
    "newark_demographics['Hispanic'] = pd.to_numeric(newark_demographics['Hispanic'])\n",
    "newark_demographics['latino_percent'] = (newark_demographics['Hispanic'] / newark_demographics['Total']) * 100\n",
    "newark_demographics['Asian'] = pd.to_numeric(newark_demographics['Asian'])\n",
    "newark_demographics['asian_percent'] = (newark_demographics['Asian'] / newark_demographics['Total']) * 100\n",
    "newark_demographics['AI/AN'] = pd.to_numeric(newark_demographics['AI/AN'])\n",
    "newark_demographics['NH/PI'] = pd.to_numeric(newark_demographics['NH/PI'])\n",
    "newark_demographics['Other_'] = pd.to_numeric(newark_demographics['Other_'])\n",
    "newark_demographics['Two Plus'] = pd.to_numeric(newark_demographics['Two Plus'])\n",
    "columns_to_sum = [\"AI/AN\", \"NH/PI\", \"Other_\", \"Two Plus\"]\n",
    "\n",
    "newark_demographics['other_percent'] = (newark_demographics[columns_to_sum].sum(axis=1) / newark_demographics['Total']) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3b3586-c258-407f-bc71-28b654cefa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "newark_demographics['geoid'] = newark_demographics['geoid'].astype('int64')\n",
    "newark_demographics = newark_demographics.dropna()\n",
    "newark_demographics.drop(columns=['state', 'county', 'block group'], axis=1, inplace=True)\n",
    "\n",
    "# convert into a gdf\n",
    "newark_demographics = gpd.GeoDataFrame(newark_demographics)\n",
    "# Convert CRS to 4326\n",
    "newark_demographics = newark_demographics.to_crs(merged_zillow.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f0d9ba-1493-42bc-a55a-7666d190b59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate centroids of census tracts\n",
    "newark_demographics['centroid'] = newark_demographics.geometry.centroid\n",
    "\n",
    "# Create a new column in census tract GeoDataFrame to store ZHVI values\n",
    "newark_demographics['ZHVI'] = None\n",
    "\n",
    "# Loop through each census tract centroid\n",
    "for idx, centroid in newark_demographics['centroid'].iteritems():\n",
    "    # Find the ZIP code polygon that contains the centroid\n",
    "    containing_zip = merged_zillow[merged_zillow.contains(centroid)].iloc[0]\n",
    "    # Get the ZHVI value of the containing ZIP code and assign it to the census tract\n",
    "    newark_demographics.at[idx, 'ZHVI'] = containing_zip['ZHVI']\n",
    "    \n",
    "# Drop unnecessary columns\n",
    "newark_demographics = newark_demographics.drop(columns=['centroid'])\n",
    "\n",
    "# Display the updated census tract GeoDataFrame\n",
    "print(newark_demographics)\n",
    "\n",
    "# Save the updated census tract GeoDataFrame as a new GeoJSON file\n",
    "newark_demographics.to_file(\"census_tracts_with_ZHVI.geojson\", driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cd350d-c443-4b4e-bc27-97a3ef235ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create final csv\n",
    "regression_df = newark_demographics\n",
    "regression_df.to_csv('regression_df.csv', index=False)\n",
    "\n",
    "regression_gdf = gpd.GeoDataFrame(regression_df, geometry='geometry')\n",
    "\n",
    "# Handle missing values in the 'ZHVI' column\n",
    "mean_ZHVI = regression_gdf[\"ZHVI\"].mean()\n",
    "regression_gdf[\"ZHVI\"].fillna(mean_ZHVI, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
