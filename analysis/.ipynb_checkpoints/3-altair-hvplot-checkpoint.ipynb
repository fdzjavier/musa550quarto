{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0b2a549-1b0b-405b-a536-36a45434eb9e",
   "metadata": {},
   "source": [
    "---\n",
    "format: \n",
    "  html:\n",
    "    toc: false\n",
    "    page-layout: full\n",
    "execute:\n",
    "    echo: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481530d3-4256-4271-b03a-97e86e37ea74",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "This section describes how the linear regression, random forest model, and cross validation were developed & compared for accuracy and efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa1a7007-56ee-4af8-9a2c-af8ddede9fc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Preprocessing\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler, PolynomialFeatures\n\u001b[1;32m---> 14\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Model selection\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "# Pipelines\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5129b9e5-c80f-4fd2-aca2-34fc2c663148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data 70/30\n",
    "train_set, test_set = train_test_split(regression_gdf, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7a7f08-d103-4345-a8ab-e00160f25514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the target labels: ZHVI\n",
    "y_train = train_set[\"ZHVI\"].values\n",
    "y_test = test_set[\"ZHVI\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81945fb0-9109-4526-970c-8e8883364117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The features\n",
    "feature_cols = [\n",
    "    \"totalpop\",\n",
    "    \"poverty\",\n",
    "    \"noeducation\",\n",
    "    \"blk_percent\",\n",
    "    \"white_percent\",\n",
    "    \"latino_percent\",\n",
    "    \"asian_percent\",\n",
    "    \"other_percent\",\n",
    "\n",
    "]\n",
    "X_train = train_set[feature_cols].values\n",
    "X_test = test_set[feature_cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d436d31d-d412-4ecd-9896-7e87d7a14863",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(\n",
    "    train_set[feature_cols].corr(), \n",
    "    cmap=\"coolwarm\", \n",
    "    annot=True, \n",
    "    vmin=-1, \n",
    "    vmax=1\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8716f469-e1ac-4ca8-b08d-12c4d8218153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a linear model pipeline\n",
    "linear_pipeline = make_pipeline(StandardScaler(), LinearRegression())\n",
    "\n",
    "# Fit on the training data\n",
    "linear_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# What are the scores?\n",
    "training_score = linear_pipeline.score(X_train, y_train)\n",
    "testing_score = linear_pipeline.score(X_test, y_test)\n",
    "\n",
    "print(f\"Linear Training Score: {training_score}\")\n",
    "print(f\"Linear Test Score: {testing_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552782d7-9ce3-46d3-8194-65c958ba15f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the 3-fold cross validation for linear regression\n",
    "scores = cross_val_score(\n",
    "    linear_pipe,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=3,\n",
    ")\n",
    "\n",
    "# Report\n",
    "print(\"CV Linear R^2 scores = \", scores)\n",
    "print(\"CV Linear Scores mean = \", scores.mean())\n",
    "print(\"CV Linear Score std dev = \", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb40c8ca-1bce-4ef6-889f-0b2abb232926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a random forest pipeline\n",
    "forest_pipeline = make_pipeline(\n",
    "    StandardScaler(),  # Pre-process step\n",
    "    RandomForestRegressor(n_estimators=100, max_depth=2, random_state=42),  # Model step\n",
    ")\n",
    "\n",
    "forest_pipeline.fit(X_train, y_train)\n",
    "\n",
    "training_score = forest_pipeline.score(X_train, y_train)\n",
    "print(f\"Random Forest Training Score = {training_score}\")\n",
    "\n",
    "test_score = forest_pipeline.score(X_test, y_test)\n",
    "print(f\"Random Forest Test Score = {test_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb52f712-2cea-4638-be5d-6612c4298818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the 10-fold cross validation\n",
    "scores = cross_val_score(\n",
    "    forest_pipeline,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=10,\n",
    ")\n",
    "\n",
    "# Report\n",
    "print(\"CV Random Forest R^2 scores = \", scores)\n",
    "print(\"CV Random Forest Scores mean = \", scores.mean())\n",
    "print(\"CV Random Forest Score std dev = \", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85369055-aff7-49bc-85e9-f8f7d1e1a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "\n",
    "# Create the data frame of important features for predicting ZHVI change levels\n",
    "\n",
    "importance = pd.DataFrame(\n",
    "    {\"Feature\": feature_cols, \"Importance\": forest_model.feature_importances_}\n",
    ").sort_values(\"Importance\")\n",
    "\n",
    "\n",
    "importance.hvplot.barh(x=\"Feature\", y=\"Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912c22ce-1925-443b-a196-35dffe1a44e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for important features in our model for predicting ZHVI change levels\n",
    "importance = pd.DataFrame(\n",
    "    {\"Feature\": feature_cols, \"Importance\": forest_model.feature_importances_}\n",
    ").sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6339814-d68a-4dab-abb5-2d20d09c887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mape(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Given a model and test features/targets, print out the \n",
    "    mean absolute error and accuracy\n",
    "    \"\"\"\n",
    "    # Make the predictions\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Absolute error\n",
    "    errors = abs(predictions - y_test)\n",
    "    avg_error = np.mean(errors)\n",
    "\n",
    "    # Mean absolute percentage error\n",
    "    mape = 100 * np.mean(errors / y_test)\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = 100 - mape\n",
    "\n",
    "    print(\"Model Performance\")\n",
    "    print(f\"Average Absolute Error: {avg_error:0.4f}\")\n",
    "    print(f\"Accuracy = {accuracy:0.2f}%.\")\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aad4c7c-eefb-4959-839a-84a3514680de",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = make_pipeline(StandardScaler(), RandomForestRegressor(random_state=42))\n",
    "\n",
    "# Fit the training set\n",
    "base_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "base_accuracy = evaluate_mape(base_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22025e5-1a4d-4831-b476-d55e732550e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = regression_gdf.loc[test_set.index]\n",
    "\n",
    "censustracts = gpd.read_file('./data/tracts2019.geojson')\n",
    "censustracts = censustracts[['GEOID','NAMELSAD', 'Pop_Total', 'Pop_Total_Poverty','Pop_Edu_NoHS_Pct','geometry']]\n",
    "censustracts = censustracts.rename(columns = {'GEOID':'geoid'})\n",
    "censustracts = censustracts.rename(columns = {'NAMELSAD':'tract'})\n",
    "censustracts = censustracts.rename(columns = {'Pop_Total':'totalpop'})\n",
    "censustracts = censustracts.rename(columns = {'Pop_Total_Poverty':'poverty'})\n",
    "censustracts = censustracts.rename(columns = {'Pop_Edu_NoHS_Pct':'noeducation'})\n",
    "censustracts['geoid'] = censustracts['geoid'].astype(np.int64)\n",
    "censustracts['tract'] = censustracts['geoid'].astype(str).str[5:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ed3e3e-66f2-4660-8f2c-d0c87b34cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['prediction'] = base_model.predict(X_test)\n",
    "data.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871d9117-2842-41d1-a16c-0b4e98a38029",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(data, censustracts, on='geoid', how ='inner')\n",
    "data = gpd.GeoDataFrame(data, geometry = 'geometry_y')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
